# -*- coding: utf-8 -*-
"""MSDS460_Assignment3[MS].ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W1a-qlAvRfHbOo5_4_fB7zjUgZOdukiZ

# MSDS460 - Assignment 3: Integer Programming Example---Algorithmic Redistricting

**Chosen State:** Virginia

Used Data Sources:
* [Wikipedia](https://en.wikipedia.org/wiki/List_of_cities_and_counties_in_Virginia#cite_note-wwwcensusgov2-8) for a list of counties and populations
* [US Census Data](https://www2.census.gov/geo/docs/reference/county_adjacency/county_adjacency2024.txt) for adjacency data
* [Virginia Administrative Boundaries](https://vgin.vdem.virginia.gov/datasets/777890ecdb634d18a02eec604db522c6/about)
* [Virginia Congressional District](https://www.arcgis.com/home/item.html?id=777890ecdb634d18a02eec604db522c6)


Group Members:
* Albert Lee
* Albert Olea
* Maddie Stapulionis
* Migus Wong
* Thomas Young

>[MSDS460 - Assignment 3: Integer Programming Example---Algorithmic Redistricting](#scrollTo=RwopTi9PA7pc)

>>[Group Discussion Points](#scrollTo=u2IZpMexBko9)

>>[Data Collection](#scrollTo=7TUZJ7Z1BR3n)

>>>[District Information](#scrollTo=qM6C53zCE-H7)

>>[County Visualization](#scrollTo=4Zk9UsgsVEMV)

>>[Base Model](#scrollTo=khD_RnZ-hnUN)

>>[Adding Contiguity](#scrollTo=Jm8Blam8w1ao)

## Group Discussion Points

* How shall we define "fairness" in the assignment of counties to congressional districts?

* The specification of constraints can be difficult, and the number of constraints can be large. Having a team of students working on this makes sense.

* There may be a need to test many alternative solutions and to "tweak" solutions to the integer program that is developed.

* Integer programs can take a long time to run and may require lots of memory. So, it is a good idea to get started on this assignment early, and it may be useful to have more than one person running the programs or trying alternative versions of programs.

## Data Collection

### District Information
"""

import pandas as pd

# URL of the Wikipedia page
url = "https://en.wikipedia.org/wiki/List_of_cities_and_counties_in_Virginia#cite_note-wwwcensusgov2-8"

# Read the first table from the URL into a pandas DataFrame
try:
  tables = pd.read_html(url)
  county_table = tables[2]
  city_table = tables[3]

except IndexError:
  print("No tables found on the page or an error occurred during scraping.")

except Exception as e:
  print(f"An error occurred: {e}")

county_table.head()

city_table.head()

county_df = county_table[['County', 'Population[8]']]
county_df.rename(columns={'Population[8]': 'Population'}, inplace=True)

city_df = city_table[['City', 'Population[11]']]
city_df.rename(columns={'Population[11]': 'Population'}, inplace=True)
city_df['City'] = city_df['City'] + " city"
city_df.head()

# Download the text file
!wget https://www2.census.gov/geo/docs/reference/county_adjacency/county_adjacency2024.txt

# Read the file into a pandas DataFrame, specifying the delimiter
try:
  adjacency_df = pd.read_csv("county_adjacency2024.txt", delimiter="|", header=0)
  print(adjacency_df.head())
except Exception as e:
  print(f"An error occurred: {e}")

county_df.rename(columns={'County': 'County/City'}, inplace=True)
city_df.rename(columns={'City': 'County/City'}, inplace=True)
df = pd.concat([county_df, city_df], ignore_index=True)
df.head()

# Filter rows where both 'County Name' and 'Neighbor Name' contain ", VA"
filtered_df = adjacency_df[
    adjacency_df['County Name'].str.contains(", VA") & adjacency_df['Neighbor Name'].str.contains(", VA")
]

# Remove ", VA" from 'County Name' and 'Neighbor Name' columns
filtered_df['County Name'] = filtered_df['County Name'].str.replace(', VA', '')
filtered_df['Neighbor Name'] = filtered_df['Neighbor Name'].str.replace(', VA', '')

# Remove rows where 'County GEOID' equals 'Neighbor GEOID'
filtered_df = filtered_df[filtered_df['County GEOID'] != filtered_df['Neighbor GEOID']]

filtered_df.head()

# Unique county names in the original DataFrame
df_counties = set(df['County/City'].unique())

# Unique county names in the filtered DataFrame
filtered_counties = set(filtered_df['County Name'].unique())

# Counties present in df but not in filtered_df
counties_only_in_df = df_counties - filtered_counties

# Counties present in filtered_df but not in df
counties_only_in_filtered = filtered_counties - df_counties

# Print the results
print("Counties present in df but not in filtered_df:")
for county in counties_only_in_df:
    print(county)

print("\nCounties present in filtered_df but not in df:")
for county in counties_only_in_filtered:
    print(county)

len(filtered_df['County Name'].unique())

aggregated_df = filtered_df.groupby(['County Name', 'County GEOID']).agg(
    {'Neighbor Name': list, 'Neighbor GEOID': list}
).reset_index()

aggregated_df.rename(columns={'Neighbor Name': 'Neighbor Names', 'Neighbor GEOID': 'Neighbor GEOIDs'}, inplace=True)

print(aggregated_df.head())

chosen_state = 'Virginia'
num_districts = 11

population_sum = df['Population'].sum()
print(f"The sum of the population is: {population_sum:,}")
print(f"The number of counties/independent cities in {chosen_state} is: {len(df)}")
print(f"The number of districts in {chosen_state} is: {num_districts}")

target_population = population_sum // num_districts
print(f"The target population is: {target_population:,} per district")

print("\nDistricts over target population:")
over_target_df = df[df['Population'] > target_population]
print(over_target_df)

df = pd.merge(df, aggregated_df, left_on='County/City', right_on='County Name', how='inner').drop(columns=['County Name'])
df.head()

df['County/City'] = df['County/City'].str.replace('city', 'City')

"""## County Visualization"""

!pip install geopandas

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

import os
!mkdir -p "/content/drive/MyDrive/ColabFiles"

import geopandas as gpd
import folium
import matplotlib.pyplot as plt
from matplotlib.colors import to_hex

gdf = gpd.read_file('/content/drive/MyDrive/MSDS460 - Decision Analytics/Module 6 Assignment/Data/VirginiaCounty.shp')

# Assuming 'gdf' is the GeoDataFrame loaded from the shapefile as in your provided code.
for index, row in gdf.iterrows():
    print(row['NAMELSAD'])

def style_function(feature):
        return {
            'fillColor': '#ffff00',
            'color': '#000000',
            'weight': 0.5,
            'fillOpacity': 0.5,
        }

    def highlight_function(feature):
        return {
            'fillColor': '#0000ff',
            'color': '#000000',
            'weight': 1,
            'fillOpacity': 0.7,
        }

# Create a folium map centered on Virginia
m = folium.Map(location=[37.54, -77.46], zoom_start=8) # Virginia coordinates

# Add a Chloropleth layer to the map
folium.Choropleth(
    geo_data=gdf,  # Your GeoJSON data
    name='Virginia Population',
    data=df,  # Your DataFrame with population data
    columns=['County/City', 'Population'],
    key_on='feature.properties.NAMELSAD', # Assuming your GeoJSON features have a 'NAME' property matching your DataFrame
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='Population',
    highlight=True,
).add_to(m)

folium.GeoJson(
        gdf,
        style_function=style_function,
        highlight_function=highlight_function,
        tooltip=folium.GeoJsonTooltip(
            fields=['NAMELSAD'],  # Display 'name' field on hover
            aliases=['County/City:'],
            sticky=True,
        )
    ).add_to(m)

# Display the map
m

gdf_district = gpd.read_file('/content/drive/MyDrive/MSDS460 - Decision Analytics/Module 6 Assignment/Data/VirginiaCongressional2010.shp')

# Function to assign a color to each district
def color_map(feature):
    # Use the district ID to select a color
    n = len(gdf_district)
    cmap = plt.cm.get_cmap('tab20', n)  # Using 'tab20' colormap with n colors
    district_id = feature['properties']['ID']  # Assumes each feature has a 'DISTRICT_ID' property
    color = cmap(district_id / n)
    return {
        'fillColor': to_hex(color),
        'color': 'black',
        'weight': 1,
        'fillOpacity': 0.5,
    }

# Create a folium map centered on Virginia
m = folium.Map(location=[37.54, -77.46], zoom_start=8)




# Add the districts layer with different colors
folium.GeoJson(

    gdf_district,
    style_function=color_map,
    highlight_function=highlight_function,
    tooltip=folium.GeoJsonTooltip(
        fields=['DISTRICT'],
        aliases=['District:'],
        sticky=True
    )
).add_to(m)

folium.GeoJson(
    gdf,
    style_function=lambda feature: {
        'fillColor': 'none',
        'color': 'black',
        'weight': 2
    },
    tooltip=folium.GeoJsonTooltip(
        fields=['NAMELSAD'],  # Display 'NAMELSAD' field on hover
        aliases=['County/City:'],
        sticky=True,
    )
).add_to(m)

# Show the map
m

"""## Base Model

In this scenario, "Fairness" is defined as having the most equitable distribution of popultion.
"""

!pip install pulp
import pulp

df = df.set_index('County GEOID')

base_model_df = df
base_model_df['Population'] = base_model_df['Population'].astype(int)
base_num_districts = 11
base_population_sum = base_model_df['Population'].sum()
base_target_population = base_population_sum // num_districts
print(f"The target population is: {target_population:,} per district with a total of {base_num_districts} districts.")


# Define the problem
prob = pulp.LpProblem("RedistrictingBase", pulp.LpMinimize)

# Convert df to a dict
county_cities = df.to_dict(orient='index')

# Extract counties/cities data
counties = list(county_cities.keys())
populations = {key: value['Population'] for key, value in county_cities.items()}

# Variables
x = pulp.LpVariable.dicts("x", [(i, j) for i in counties for j in range(base_num_districts)], cat='Binary')

# Auxiliary variables to represent absolute differences
abs_diff = pulp.LpVariable.dicts("abs_diff", [j for j in range(base_num_districts)], lowBound=0, cat='Continuous')

# Objective function: Minimize the sum of absolute differences
prob += pulp.lpSum(abs_diff[j] for j in range(base_num_districts))

# Constraints
# Each county must be in exactly one district
for i in counties:
    prob += pulp.lpSum(x[i, j] for j in range(base_num_districts)) == 1


# Constraints to link absolute differences with district populations
for j in range(base_num_districts):
    district_pop = pulp.lpSum([populations[i] * x[(i, j)] for i in counties])
    prob += district_pop - target_population <= abs_diff[j]  # Upper bound
    prob += target_population - district_pop <= abs_diff[j]  # Lower bound

# Solve the problem
print("\n\nSolving Problem\n\n")
prob.solve()

# Output status of problem
print(f"Problem Status: {pulp.LpStatus[prob.status]}\n")

# Output the results
for i in counties:
    for j in range(base_num_districts):
        if pulp.value(x[i, j]) == 1:
            print(f"County {county_cities[i]['County/City']} (GEOID: {i}) is in District {j}")

district_assignments = {}
for i in counties:
    for j in range(base_num_districts):
        if pulp.value(x[i, j]) == 1:
            district_assignments[i] = j + 1

# Create a new column 'District' in base_model_df
base_model_df['District'] = base_model_df.index.map(district_assignments)

# Handle counties that were not assigned to a district (if any)
base_model_df['District'] = base_model_df['District'].fillna(-1)

# Group by district and sum the population
district_populations = base_model_df.groupby('District')['Population'].sum()

# Get the county names for each district
district_counties = base_model_df.groupby('District')['County/City'].apply(list)

# Combine the results into a DataFrame
result_df = pd.DataFrame({'Population': district_populations, 'Counties': district_counties})

result_df

district_mapping_base = base_model_df['District'].to_dict()
gdf_base = gdf.set_index('STCOFIPS')
gdf_base.index = gdf_base.index.astype(int)

# Map the district numbers to the gdf_contiguous_df based on the GEOID
gdf_base['District'] = gdf_base.index.map(district_mapping_base)


# Function to assign a color to each district
def color_map_base(feature):
    # Use the district ID to select a color
    n = 11
    cmap = plt.cm.get_cmap('tab20', n)  # Using 'tab20' colormap with n colors
    district_id = feature['properties']['District']
    color = cmap(district_id / n)
    return {
        'fillColor': to_hex(color),
        'color': 'black',
        'weight': 1,
        'fillOpacity': 0.5,
    }

# Create a folium map centered on Virginia
m = folium.Map(location=[37.54, -77.46], zoom_start=8)

# Add GeoJSON layer with custom style function using color_map_contiguous
folium.GeoJson(
    gdf_base,
    style_function=color_map_base,
    tooltip=folium.GeoJsonTooltip(
        fields=['NAMELSAD', 'District'],  # Display 'NAMELSAD' and 'District' fields on hover
        aliases=['County/City:', 'District:'],
        sticky=True,
    )
).add_to(m)

m

# Create a folium map centered on Virginia
m = folium.Map(location=[37.54, -77.46], zoom_start=8)

# Add the counties layer with colors based on the district assignments
folium.Choropleth(
    geo_data=gdf,
    name='Virginia Districts',
    data=base_model_df,
    columns=['County/City', 'District'],  # Use 'NAMELSAD' to match GeoJSON and 'District' for coloring
    key_on='feature.properties.NAMELSAD',
    fill_color='Set1',  # Choose a categorical colormap
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='District',
    highlight=True,
).add_to(m)

folium.GeoJson(
    gdf,
    style_function=lambda feature: {
        'fillColor': 'black',
        'color': 'black',
        'weight': 2,
        'fill_opacity':0.1
    },
    tooltip=folium.GeoJsonTooltip(
        fields=['NAMELSAD'],  # Display 'NAMELSAD' field on hover
        aliases=['County/City:'],
        sticky=True,
    )
).add_to(m)

# Show the map
m

"""## Adding Contiguity"""

gdf['centroid'] = gdf.geometry.centroid
gdf['X'] = gdf['centroid'].x
gdf['Y'] = gdf['centroid'].y

gdf_wgs84 = gdf.to_crs(epsg=4326)
# Get the x-coordinate of the centroid of each geometry
gdf_wgs84['x'] = gdf_wgs84.geometry.centroid.x
gdf_wgs84['y'] = gdf_wgs84.geometry.centroid.y
gdf_wgs84.drop(columns=['X','Y'], inplace=True)
gdf.drop(columns=['X','Y','centroid'], inplace=True)
gdf_wgs84.head()

!pip install geopy
# what is the "distance" between Payne County (node 0), Oklahoma County (node 15), and Tulsa County (node 23)?
from geopy.distance import geodesic

# Find the coordinates for Accomack and Albemarle counties
accomack_coords = gdf_wgs84[gdf_wgs84['NAMELSAD'] == 'Accomack County']
albemarle_coords = gdf_wgs84[gdf_wgs84['NAMELSAD'] == 'Albemarle County']

if not accomack_coords.empty and not albemarle_coords.empty:
  accomack_coords = (accomack_coords['y'].iloc[0], accomack_coords['x'].iloc[0])
  albemarle_coords = (albemarle_coords['y'].iloc[0], albemarle_coords['x'].iloc[0])

  # Calculate the distance using geopy.distance
  distance = geodesic(accomack_coords, albemarle_coords).miles
  print(f"The distance between Accomack County and Albemarle County is: {distance} miles")
else:
  print("Accomack or Albemarle County not found in the GeoDataFrame.")

# Set the index of gdf_wgs84 to match the index of df
gdf_wgs84 = gdf_wgs84.set_index(df.index)
gdf_wgs84.head()

dist = dict()
for i in gdf_wgs84.index:
    for j in gdf_wgs84.index:
        coords_i = (gdf_wgs84.loc[i, 'y'], gdf_wgs84.loc[i, 'x'])
        coords_j = (gdf_wgs84.loc[j, 'y'], gdf_wgs84.loc[j, 'x'])
        dist[i,j] = geodesic(coords_i, coords_j).miles

dist[51001,51003]

# Let's impose a 10% population deviation (+/- 15%)
deviation = 0.30

import math
k = 11          # number of districts
total_population = df['Population'].sum()

L = math.ceil((1-deviation/2)*total_population/k)
U = math.floor((1+deviation/2)*total_population/k)
print("Using L =",L,"and U =",U,"and k =",k)

import networkx as nx

prob = pulp.LpProblem("Redistricting", pulp.LpMinimize)

# create x[i,j] variable which equals one when county i
#    is assigned to (the district centered at) county j
x = pulp.LpVariable.dicts("x", [(i, j) for i in counties for j in counties], cat='Binary')

# Objective function: Minimize the sum of squared distances weighted by population
prob += pulp.lpSum(dist[i, j]**2 * base_model_df.loc[i, 'Population'] * x[i, j] for i in counties for j in counties)

# add constraints saying that each county i is assigned to one district
for i in counties:
    prob += pulp.lpSum(x[i, j] for j in counties) == 1

# add constraint saying there should be k district centers
prob += pulp.lpSum(x[j, j] for j in counties) == k

# #Lower bound constraint
# for j in counties:
#     prob += pulp.lpSum(base_model_df.loc[i, 'Population'] * x[i, j] for i in counties) >= L * x[j, j]

# Add the constraint to ensure that if i is assigned to j, then j must be a district center
for i in counties:
    for j in counties:
        prob += x[i, j] <= x[j, j]

# Create a directed graph
DG = nx.DiGraph()

# Add nodes to the graph (counties/cities)
for county in df.index:
    DG.add_node(county)

# Add edges based on adjacency information
for index, row in df.iterrows():
    county = index
    neighbors = row['Neighbor Names']
    neighbor_geoids = row['Neighbor GEOIDs']

    for i, neighbor in enumerate(neighbors):
      neighbor_geoid = neighbor_geoids[i]
      # Add directed edges between the county and its neighbors.
      if neighbor_geoid in DG:
        DG.add_edge(county, neighbor_geoid)
        DG.add_edge(neighbor_geoid, county)

# Now you have a directed graph 'G' representing the relationships between counties/cities
print(f"Number of nodes in the graph: {DG.number_of_nodes()}")
print(f"Number of edges in the graph: {DG.number_of_edges()}")

# Add flow variables
f = pulp.LpVariable.dicts("f", [(j, u, v) for j in DG.nodes for u, v in DG.edges], lowBound=0, cat='Continuous')
M = len(DG.nodes) - 1

# Add constraint saying that node j cannot receive flow of its own type
for j in DG.nodes:
    for u in DG.neighbors(j):
        prob += pulp.lpSum(f[j, u, j] for u in DG.neighbors(j)) == 0

# Add constraints saying that node i can receive flow of type j only if i is assigned to j
for i in DG.nodes:
    for j in DG.nodes:
        if i != j:
            prob += pulp.lpSum(f[j, u, i] for u in DG.neighbors(i) if (j, u, i) in f) <= M * x[i, j]

# If i is assigned to j, then i should consume one unit of j flow. Otherwise, i should consume no units of j flow.
for i in DG.nodes:
    for j in DG.nodes:
        if i != j:
            prob += pulp.lpSum(f[j, u, i] - f[j, i, u] for u in DG.neighbors(i) if (j, u, i) in f and (j, i, u) in f) == x[i, j]

# Solve the problem with detailed output
print("\n\nSolving Problem\n\n")
prob.solve(pulp.PULP_CBC_CMD(msg=True))
# Output status of problem
print(f"Problem Status: {pulp.LpStatus[prob.status]}\n")

# Retrieve the districts and their populations
centers = [j for j in counties if pulp.value(x[j, j]) > 0.5]
districts = [[i for i in counties if pulp.value(x[i, j]) > 0.5] for j in centers]
district_counties = [[base_model_df.loc[i, 'County/City'] for i in districts[j]] for j in range(k)]
district_populations = [sum(base_model_df.loc[i, 'Population'] for i in districts[j]) for j in range(k)]

# Print the results
print("Centers:", centers)
print("Districts:", districts)
print("District Counties:", district_counties)
print("District Populations:", district_populations)

base_model_contiguous_df = base_model_df.drop(columns=['District'])

for n,district in enumerate(districts):
    for county in district:
        base_model_contiguous_df.loc[county,'District'] = n+1
base_model_contiguous_df['District'] = base_model_contiguous_df['District'].astype(int)
base_model_contiguous_df

# Group by district and sum the population
district_populations = base_model_contiguous_df.groupby('District')['Population'].sum()

# Get the county names for each district
district_counties = base_model_contiguous_df.groupby('District')['County/City'].apply(list)

# Combine the results into a DataFrame
result_df = pd.DataFrame({'Population': district_populations, 'Counties': district_counties})
result_df['Deviation'] = (result_df['Population'] - target_population)
result_df

district_mapping_contiguous = base_model_contiguous_df['District'].to_dict()
gdf_contiguous_df = gdf.set_index('STCOFIPS')
gdf_contiguous_df.index = gdf_contiguous_df.index.astype(int)

# Map the district numbers to the gdf_contiguous_df based on the GEOID
gdf_contiguous_df['District'] = gdf_contiguous_df.index.map(district_mapping_contiguous)

# Function to assign a color to each district
def color_map_contiguous(feature):
    # Use the district ID to select a color
    n = 11
    cmap = plt.cm.get_cmap('tab20', n)  # Using 'tab20' colormap with n colors
    district_id = feature['properties']['District']
    color = cmap(district_id / n)
    return {
        'fillColor': to_hex(color),
        'color': 'black',
        'weight': 1,
        'fillOpacity': 0.5,
    }

# Create a folium map centered on Virginia
m = folium.Map(location=[37.54, -77.46], zoom_start=8)

# Add GeoJSON layer with custom style function using color_map_contiguous
folium.GeoJson(
    gdf_contiguous_df,
    style_function=color_map_contiguous,
    tooltip=folium.GeoJsonTooltip(
        fields=['NAMELSAD', 'District'],  # Display 'NAMELSAD' and 'District' fields on hover
        aliases=['County/City:', 'District:'],
        sticky=True,
    )
).add_to(m)

m

"""# Adding Historical Voting Information"""

try:
    election_df = pd.read_csv("https://historical.elections.virginia.gov/elections/download/144567/precincts_include:0/")
    print(election_df.head())
except Exception as e:
    print(f"An error occurred: {e}")

# Drop the first row
election_df = election_df.drop(0).reset_index(drop=True)

# Drop the second and third columns
election_df = election_df.drop(['Unnamed: 1', 'Unnamed: 2'], axis=1)

# Manually specify the column names (adjust these as per your dataset)
election_df.columns = ['County/City', 'Democratic', 'Republican', 'Libertarian', 'All Others','Total Votes']

# Drop the last row
election_df = election_df.drop(election_df.index[-1])

# Set the columns as integers
election_df['Democratic'] = pd.to_numeric(election_df['Democratic'].str.replace(',', ''), errors='coerce').astype('Int64')
election_df['Republican'] = pd.to_numeric(election_df['Republican'].str.replace(',', ''), errors='coerce').astype('Int64')
election_df['Libertarian'] = pd.to_numeric(election_df['Libertarian'].str.replace(',', ''), errors='coerce').astype('Int64')
election_df['All Others'] = pd.to_numeric(election_df['All Others'].str.replace(',', ''), errors='coerce').astype('Int64')
election_df['Total Votes'] = pd.to_numeric(election_df['Total Votes'].str.replace(',', ''), errors='coerce').astype('Int64')
election_df['County/City'] = election_df['County/City'].astype(str)

# Now df will have the desired column names, second and third columns removed, and the last row dropped
election_df.head()

# Unique county names in the original DataFrame
df_counties = set(df['County/City'].unique())

# Unique county names in the election DataFrame
election_counties = set(election_df['County/City'].unique())

# Counties present in df but not in filtered_df
counties_only_in_df = df_counties - election_counties

# Counties present in filtered_df but not in df
counties_only_in_election = election_counties - df_counties

# Print the results
print("Counties present in df but not in election_df:")
for county in counties_only_in_df:
    print(county)

print("\nCounties present in election_df but not in df:")
for county in counties_only_in_election:
    print(county)

len(election_df['County/City'].unique())

# Ensure consistent county names
election_df['County/City'] = election_df['County/City'].str.strip()

# Merge election_df with df to get County GEOID
election_df = election_df.merge(df.reset_index()[['County GEOID', 'County/City']], on='County/City', how='left')

# Set County GEOID as index
election_df.set_index('County GEOID', inplace=True)

# Convert 'election_df' to a dictionary for easier access
election_data = election_df.copy()

# Create a mapping of 'County GEOID' to its political proportions
political_proportions = {
    idx: {
        'Democratic': election_data.loc[idx, 'Democratic'] / election_data.loc[idx, 'Total Votes'],
        'Republican': election_data.loc[idx, 'Republican'] / election_data.loc[idx, 'Total Votes'],
        'Libertarian': election_data.loc[idx, 'Libertarian'] / election_data.loc[idx, 'Total Votes'],
        'All Others': election_data.loc[idx, 'All Others'] / election_data.loc[idx, 'Total Votes']
    }
    for idx in election_data.index if idx in election_data.index
}

# Get list of counties (GEOIDs)
counties = list(df.index)

# Define LP problem
prob = pulp.LpProblem("Redistricting", pulp.LpMinimize)

# Define decision variables
x = pulp.LpVariable.dicts("x", [(i, j) for i in counties for j in counties], cat='Binary')
# x = pulp.LpVariable.dicts("x", [(i, j) for i in counties for j in range(base_num_districts)], cat='Binary')


# Objective function: Minimize the sum of squared distances weighted by population
# prob += pulp.lpSum(dist[i, j]**2 * base_model_df.loc[i, 'Population'] * x[i, j] for i in counties for j in counties)
prob += pulp.lpSum(dist[i, j]**2 * base_model_df.loc[i, 'Population'] * x[i, j] for i in counties for j in counties)

# Assign each county to one district
for i in counties:
    prob += pulp.lpSum(x[i, j] for j in counties) == 1

# Ensure k district centers
prob += pulp.lpSum(x[j, j] for j in counties) == k

# Add flow constraints (ensure contiguity)
f = pulp.LpVariable.dicts("f", [(j, u, v) for j in DG.nodes for u, v in DG.edges], lowBound=0, cat='Continuous')
for j in DG.nodes:
    for u in DG.neighbors(j):
        prob += pulp.lpSum(f[j, u, j] for u in DG.neighbors(j)) == 0

# Political Fairness Objective: Balance political compositions
for i in counties:
  prob += pulp.lpSum((political_proportions[i]['Democratic'] - political_proportions[i]['Republican']) * x[i, j])

# Ensure valid district assignment
for i in counties:
    for j in counties:
        prob += x[i, j] <= x[j, j]

# Solve problem
prob.solve()

# Output status
print(f"Problem Status: {pulp.LpStatus[prob.status]}\n")

# # Store district assignments
# district_assignments = {i: j+1 for i in counties for j in counties if pulp.value(x[i, j]) == 1}

# # Assign districts in df
# df['District'] = df.index.map(district_assignments)

# election_df = election_df.set_index("County GEOID")

# Retrieve the districts and their populations
centers = [j for j in counties if pulp.value(x[j, j]) > 0.5]
districts = [[i for i in counties if pulp.value(x[i, j]) > 0.5] for j in centers]
district_counties = [[base_model_df.loc[i, 'County/City'] for i in districts[j]] for j in range(k)]
district_populations = [sum(base_model_df.loc[i, 'Population'] for i in districts[j]) for j in range(k)]
district_republicans = [sum(election_df.loc[i, 'Republican'] for i in districts[j]) for j in range(k)]
district_democrats = [sum(election_df.loc[i, 'Democratic'] for i in districts[j]) for j in range(k)]

# Print the results
print("Centers:", centers)
print("Districts:", districts)
print("District Counties:", district_counties)
print("District Populations:", district_populations)
print("District Republicans:", district_republicans)
print("District Democrats:", district_democrats)

base_model_election_df = base_model_df.drop(columns=['District'])

for n,district in enumerate(districts):
    for county in district:
        base_model_election_df.loc[county,'District'] = n+1
base_model_election_df['District'] = base_model_election_df['District'].astype(int)

base_model_election_df = base_model_election_df.join(election_df, how="inner", lsuffix="_base", rsuffix="_election")

base_model_election_df.head(1)

# Group by district and sum the population
district_populations = base_model_election_df.groupby('District')['Population'].sum()
district_republican = base_model_election_df.groupby('District')['Republican'].sum()
district_democratic = base_model_election_df.groupby('District')['Democratic'].sum()

# Get the county names for each district
base_model_election_df = base_model_election_df.rename(columns={"County/City_base": "County/City"})
district_counties = base_model_election_df.groupby('District')['County/City'].apply(list)

# Combine the results into a DataFrame
result_election = pd.DataFrame({'Population': district_populations
                          , 'Republican': district_republican
                          , 'Democratic': district_democratic
                          , 'Counties': district_counties})
result_election['Pop Deviation'] = (result_election['Population'] - target_population)
result_election

district_mapping_base = base_model_election_df['District'].to_dict()
gdf_base = gdf.set_index('STCOFIPS')
gdf_base.index = gdf_base.index.astype(int)

# Map the district numbers to the gdf_contiguous_df based on the GEOID
gdf_base['District'] = gdf_base.index.map(district_mapping_base)


# Function to assign a color to each district
def color_map_base(feature):
    # Use the district ID to select a color
    n = 11
    cmap = plt.cm.get_cmap('tab20', n)  # Using 'tab20' colormap with n colors
    district_id = feature['properties']['District']
    color = cmap(district_id / n)
    return {
        'fillColor': to_hex(color),
        'color': 'black',
        'weight': 1,
        'fillOpacity': 0.5,
    }

# Create a folium map centered on Virginia
m = folium.Map(location=[37.54, -77.46], zoom_start=8)

# Add GeoJSON layer with custom style function using color_map_contiguous
folium.GeoJson(
    gdf_base,
    style_function=color_map_base,
    tooltip=folium.GeoJsonTooltip(
        fields=['NAMELSAD', 'District'],  # Display 'NAMELSAD' and 'District' fields on hover
        aliases=['County/City:', 'District:'],
        sticky=True,
    )
).add_to(m)

m

"""## Attempt #2"""

# import pulp
# import networkx as nx

# # Step 1: Prepare election data and political proportions
# election_data = election_df.copy()

# # Create a mapping of 'County GEOID' to its political proportions
# political_proportions = {
#     idx: {
#         'Democratic': election_data.loc[idx, 'Democratic'] / election_data.loc[idx, 'Total Votes'],
#         'Republican': election_data.loc[idx, 'Republican'] / election_data.loc[idx, 'Total Votes'],
#         'Libertarian': election_data.loc[idx, 'Libertarian'] / election_data.loc[idx, 'Total Votes'],
#         'All Others': election_data.loc[idx, 'All Others'] / election_data.loc[idx, 'Total Votes']
#     }
#     for idx in election_data.index if idx in election_data.index
# }

# # Get list of counties (GEOIDs)
# counties = list(df.index)

# # Step 2: Create the redistricting problem
# prob = pulp.LpProblem("Redistricting", pulp.LpMinimize)

# # Define decision variables
# x = pulp.LpVariable.dicts("x", [(i, j) for i in counties for j in counties], cat='Binary')

# # Step 3: Objective function: Minimize the sum of squared distances weighted by population and political fairness
# prob += pulp.lpSum(dist[i, j]**2 * base_model_df.loc[i, 'Population'] * x[i, j] for i in counties for j in counties)

# # Add political fairness objective: minimize political imbalance in districts
# # for j in counties:  # Loop over each district
# #     prob += pulp.lpSum(
# #         (political_proportions[i]['Democratic'] - political_proportions[i]['Republican']) * x[i, j]
# #         for i in counties
# #     )
# # Introduce slack variables for political imbalance
# slack_democratic = pulp.LpVariable.dicts("SlackDemocratic", counties, lowBound=0)
# slack_republican = pulp.LpVariable.dicts("SlackRepublican", counties, lowBound=0)

# # Modify the political fairness term to allow for some imbalance
# for j in counties:
#     prob += pulp.lpSum(
#         (political_proportions[i]['Democratic'] - political_proportions[i]['Republican']) * x[i, j]
#         for i in counties
#     ) + pulp.lpSum(slack_democratic[i] for i in counties) + pulp.lpSum(slack_republican[i] for i in counties)


# # Modify the political fairness term to allow for some imbalance
# for j in counties:
#     prob += pulp.lpSum(
#         (political_proportions[i]['Democratic'] - political_proportions[i]['Republican']) * x[i, j]
#         for i in counties
#     ) + pulp.lpSum(slack_democratic[i] for i in counties) + pulp.lpSum(slack_republican[i] for i in counties)


# # Step 4: Constraints
# # 4.1: Assign each county to one district
# for i in counties:
#     prob += pulp.lpSum(x[i, j] for j in counties) == 1  # Each county is assigned to one district

# # 4.2: Ensure exactly k district centers
# prob += pulp.lpSum(x[j, j] for j in counties) == k  # Exactly k district centers

# # 4.3: Congruity: If county i is assigned to district j, then district j must be a district center
# for i in counties:
#     for j in counties:
#         prob += x[i, j] <= x[j, j]  # District center must be chosen if a county is assigned to it

# # 4.4: Contiguity: Ensure each district is contiguous
# DG = nx.DiGraph()

# # Add nodes (counties)
# for county in df.index:
#     DG.add_node(county)

# # Add edges based on adjacency (neighbors)
# for index, row in df.iterrows():
#     county = index
#     neighbors = row['Neighbor Names']
#     neighbor_geoids = row['Neighbor GEOIDs']

#     for i, neighbor in enumerate(neighbors):
#         neighbor_geoid = neighbor_geoids[i]
#         if neighbor_geoid in DG:
#             DG.add_edge(county, neighbor_geoid)
#             DG.add_edge(neighbor_geoid, county)

# # Add flow variables for adjacency constraints
# f = pulp.LpVariable.dicts("f", [(j, u, v) for j in DG.nodes for u, v in DG.edges], lowBound=0, cat='Continuous')

# # 4.5: Flow constraints: Ensuring contiguity (no isolated counties in districts)
# for j in DG.nodes:
#     for u in DG.neighbors(j):
#         prob += pulp.lpSum(f[j, u, j] for u in DG.neighbors(j)) == 0

# # 4.6: Political fairness: Balanced political proportions across districts
# for i in counties:
#     for j in counties:
#         prob += pulp.lpSum((political_proportions[i]['Democratic'] - political_proportions[i]['Republican']) * x[i, j]) <= M * x[i, j]

# # Step 5: Solve the problem
# prob.solve()

# # Step 6: Output the status of the solution
# print(f"Problem Status: {pulp.LpStatus[prob.status]}\n")

# # # Step 7: Extract and print the district assignments
# # district_assignments = {i: j+1 for i in counties for j in counties if pulp.value(x[i, j]) == 1}
# # df['District'] = df.index.map(district_assignments)

# # # Step 8: Display the district assignments
# # print(df[['District', 'County/City']])

election_data = election_df.copy()

# Create a mapping of 'County GEOID' to its political proportions
political_proportions = {
    idx: {
        'Democratic': election_data.loc[idx, 'Democratic'] / election_data.loc[idx, 'Total Votes'],
        'Republican': election_data.loc[idx, 'Republican'] / election_data.loc[idx, 'Total Votes'],
        'Libertarian': election_data.loc[idx, 'Libertarian'] / election_data.loc[idx, 'Total Votes'],
        'All Others': election_data.loc[idx, 'All Others'] / election_data.loc[idx, 'Total Votes']
    }
    for idx in election_data.index if idx in election_data.index
}

counties = list(df.index)

# Define the problem
prob = pulp.LpProblem("Redistricting", pulp.LpMinimize)

# Define decision variables
x = pulp.LpVariable.dicts("x", [(i, j) for i in counties for j in counties], cat='Binary')

# Objective function: Minimize the sum of squared distances weighted by population and political fairness
# Reduced weight for political fairness term to prioritize congruity
political_fairness_weight = 1

prob += pulp.lpSum(dist[i, j]**2 * base_model_df.loc[i, 'Population'] * x[i, j] for i in counties for j in counties) + \
        political_fairness_weight * pulp.lpSum(
            (political_proportions[i]['Democratic'] - political_proportions[i]['Republican']) * x[i, j]
            for i in counties for j in counties
        )

# Assign each county to one district
for i in counties:
    prob += pulp.lpSum(x[i, j] for j in counties) == 1  # Each county is assigned to exactly one district

# Ensure exactly k district centers
prob += pulp.lpSum(x[j, j] for j in counties) == k  # Exactly k district centers

# Congruity: If county i is assigned to district j, then district j must be a district center
for i in counties:
    for j in counties:
        prob += x[i, j] <= x[j, j]  # District center must be chosen if a county is assigned to it

# Ensure each district is contiguous
DG = nx.DiGraph()

# Add nodes (counties)
for county in df.index:
    DG.add_node(county)

# Add edges based on adjacency (neighbors)
for index, row in df.iterrows():
    county = index
    neighbors = row['Neighbor Names']
    neighbor_geoids = row['Neighbor GEOIDs']

    for i, neighbor in enumerate(neighbors):
        neighbor_geoid = neighbor_geoids[i]
        if neighbor_geoid in DG:
            DG.add_edge(county, neighbor_geoid)
            DG.add_edge(neighbor_geoid, county)

# Add flow variables for adjacency constraints
f = pulp.LpVariable.dicts("f", [(j, u, v) for j in DG.nodes for u, v in DG.edges], lowBound=0, cat='Continuous')

# Flow constraints: Ensuring contiguity (no isolated counties in districts)
for j in DG.nodes:
    for u in DG.neighbors(j):
        prob += pulp.lpSum(f[j, u, j] for u in DG.neighbors(j)) == 0

# Political fairness: Balanced political proportions across districts
for i in counties:
    for j in counties:
        prob += pulp.lpSum((political_proportions[i]['Democratic'] - political_proportions[i]['Republican']) * x[i, j]) <= M * x[i, j]

prob.solve()
print(f"Problem Status: {pulp.LpStatus[prob.status]}\n")

# # Step 7: Extract and print the district assignments
# district_assignments = {i: j+1 for i in counties for j in counties if pulp.value(x[i, j]) == 1}
# df['District'] = df.index.map(district_assignments)

# # Step 8: Display the district assignments
# print(df[['District', 'County/City']])

# election_df = election_df.set_index("County GEOID")

# Retrieve the districts and their populations
centers = [j for j in counties if pulp.value(x[j, j]) > 0.5]
districts = [[i for i in counties if pulp.value(x[i, j]) > 0.5] for j in centers]
district_counties = [[base_model_df.loc[i, 'County/City'] for i in districts[j]] for j in range(k)]
district_populations = [sum(base_model_df.loc[i, 'Population'] for i in districts[j]) for j in range(k)]
district_republicans = [sum(election_df.loc[i, 'Republican'] for i in districts[j]) for j in range(k)]
district_democrats = [sum(election_df.loc[i, 'Democratic'] for i in districts[j]) for j in range(k)]

# Print the results
print("Centers:", centers)
print("Districts:", districts)
print("District Counties:", district_counties)
print("District Populations:", district_populations)
print("District Republicans:", district_republicans)
print("District Democrats:", district_democrats)

base_model_election_df = base_model_df.drop(columns=['District'])

for n,district in enumerate(districts):
    for county in district:
        base_model_election_df.loc[county,'District'] = n+1
base_model_election_df['District'] = base_model_election_df['District'].astype(int)

base_model_election_df = base_model_election_df.join(election_df, how="inner", lsuffix="_base", rsuffix="_election")

base_model_election_df.head(1)

# Group by district and sum the population
district_populations = base_model_election_df.groupby('District')['Population'].sum()
district_republican = base_model_election_df.groupby('District')['Republican'].sum()
district_democratic = base_model_election_df.groupby('District')['Democratic'].sum()

# Get the county names for each district
base_model_election_df = base_model_election_df.rename(columns={"County/City_base": "County/City"})
district_counties = base_model_election_df.groupby('District')['County/City'].apply(list)

# Combine the results into a DataFrame
result_election = pd.DataFrame({'Population': district_populations
                          , 'Republican': district_republican
                          , 'Democratic': district_democratic
                          , 'Counties': district_counties})
result_election['Pop Deviation'] = (result_election['Population'] - target_population)
result_election

district_mapping_base = base_model_election_df['District'].to_dict()
gdf_base = gdf.set_index('STCOFIPS')
gdf_base.index = gdf_base.index.astype(int)

# Map the district numbers to the gdf_contiguous_df based on the GEOID
gdf_base['District'] = gdf_base.index.map(district_mapping_base)


# Function to assign a color to each district
def color_map_base(feature):
    # Use the district ID to select a color
    n = 11
    cmap = plt.cm.get_cmap('tab20', n)  # Using 'tab20' colormap with n colors
    district_id = feature['properties']['District']
    color = cmap(district_id / n)
    return {
        'fillColor': to_hex(color),
        'color': 'black',
        'weight': 1,
        'fillOpacity': 0.5,
    }

# Create a folium map centered on Virginia
m = folium.Map(location=[37.54, -77.46], zoom_start=8)

# Add GeoJSON layer with custom style function using color_map_contiguous
folium.GeoJson(
    gdf_base,
    style_function=color_map_base,
    tooltip=folium.GeoJsonTooltip(
        fields=['NAMELSAD', 'District'],  # Display 'NAMELSAD' and 'District' fields on hover
        aliases=['County/City:', 'District:'],
        sticky=True,
    )
).add_to(m)

m

"""# Adding Demographics Constraints"""

import pandas as pd

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

import os
!mkdir -p "/content/drive/MyDrive/ColabFiles"

# Load demographic data
demographics_df = pd.read_csv('/content/drive/MyDrive/MSDS460 - Decision Analytics/Module 6 Assignment/Data/cc-est2023-agesex.csv')

# Check if 'STATE' exists before filtering
demographics_df = demographics_df[demographics_df['STATE'] == 51]

# Select the correct column names from demographics_df
demographics_df = demographics_df[['COUNTY', 'POPESTIMATE', 'POPEST_MALE', 'POPEST_FEM','UNDER5_TOT','AGE85PLUS_TOT']]

# Rename columns to match expected names
demographics_df.rename(columns={'POPESTIMATE': 'TOT_POP', 'POPEST_MALE': 'TOT_MALE', 'POPEST_FEM': 'TOT_FEMALE', 'UNDER5_TOT': 'AGE_UNDER5','AGE85PLUS_TOT': 'AGE_85PLUS'}, inplace=True)

# Check the first few rows
print(demographics_df.head())

# Ensure COUNTY is a string and keep last 3 digits
demographics_df['COUNTY'] = demographics_df['COUNTY'].astype(str).str.zfill(3)

# Add "51" prefix to match STCOFIPS format
demographics_df['COUNTY'] = '51' + demographics_df['COUNTY']

# Convert back to integer for merging
demographics_df['COUNTY'] = demographics_df['COUNTY'].astype(int)

print(demographics_df[['COUNTY']].head(10))  # Should show: 51001, 51003, etc.

print(demographics_df.columns)

# Ensure STCOFIPS and COUNTY are integers for a proper merge
gdf['STCOFIPS'] = gdf['STCOFIPS'].astype(int)
demographics_df['COUNTY'] = demographics_df['COUNTY'].astype(int)

# Merge datasets using the correct column
base_model_df = gdf[['STCOFIPS', 'NAME', 'geometry']].merge(demographics_df[['COUNTY', 'TOT_POP', 'TOT_MALE', 'TOT_FEMALE', 'AGE_UNDER5', 'AGE_85PLUS']],
                          left_on='STCOFIPS', right_on='COUNTY',
                          how='left')

# Ensure demographic columns are integers
for col in ['TOT_POP', 'TOT_MALE', 'TOT_FEMALE', 'AGE_UNDER5', 'AGE_85PLUS']:
    base_model_df[col] = base_model_df[col].fillna(0).astype(int)

# Verify the merge and check for missing values
print(base_model_df[['STCOFIPS', 'NAME', 'TOT_POP', 'TOT_MALE', 'TOT_FEMALE', 'AGE_UNDER5', 'AGE_85PLUS']].head(10))
print(base_model_df['TOT_POP'].isna().sum(), "missing values found in TOT_POP")
print(base_model_df['TOT_MALE'].isna().sum(), "missing values found in TOT_MALE")
print(base_model_df['TOT_FEMALE'].isna().sum(), "missing values found in TOT_FEMALE")
print(base_model_df['AGE_UNDER5'].isna().sum(), "missing values found in AGE_UNDER5")
print(base_model_df['AGE_85PLUS'].isna().sum(), "missing values found in AGE_85PLUS")

# Define number of districts
num_districts = 11
total_population = base_model_df["TOT_POP"].sum()
target_population = total_population // num_districts
allowed_deviation = 0.15 * target_population  # Allow 15% deviation

# Target Demographics
target_male_population = base_model_df["TOT_MALE"].sum() // num_districts
target_female_population = base_model_df["TOT_FEMALE"].sum() // num_districts
target_under5_population = base_model_df["AGE_UNDER5"].sum() // num_districts
target_over85_population = base_model_df["AGE_85PLUS"].sum() // num_districts

# Create County List
counties = base_model_df["STCOFIPS"].tolist()
populations = dict(zip(counties, base_model_df["TOT_POP"]))
male_population = dict(zip(counties, base_model_df["TOT_MALE"]))
female_population = dict(zip(counties, base_model_df["TOT_FEMALE"]))
age_under5 = dict(zip(counties, base_model_df["AGE_UNDER5"]))
age_85plus = dict(zip(counties, base_model_df["AGE_85PLUS"]))

# Create an adjacency matrix using spatial operations
def create_adjacency_matrix(gdf):
    adjacency = gdf.geometry.apply(lambda x: gdf.geometry.touches(x))
    adjacency_matrix = adjacency.astype(int)  # Convert to 1/0 matrix
    adjacency_matrix.columns = gdf['STCOFIPS'].values
    adjacency_matrix.index = gdf['STCOFIPS'].values
    return adjacency_matrix

# Create adjacency matrix
adjacency_matrix = create_adjacency_matrix(gdf)

print(adjacency_matrix.head(10))  # Verify adjacency relationships

# Define the optimization problem
prob = pulp.LpProblem("Redistricting", pulp.LpMinimize)

# Decision Variables: Assign County i to District j
x = pulp.LpVariable.dicts("x", [(i, j) for i in counties for j in range(num_districts)], cat='Binary')

# Absolute Difference Variables (for balance constraints)
abs_diff_pop = pulp.LpVariable.dicts("abs_diff_pop", range(num_districts), lowBound=0, cat='Continuous')
abs_diff_male = pulp.LpVariable.dicts("abs_diff_male", range(num_districts), lowBound=0, cat='Continuous')
abs_diff_female = pulp.LpVariable.dicts("abs_diff_female", range(num_districts), lowBound=0, cat='Continuous')
abs_diff_under5 = pulp.LpVariable.dicts("abs_diff_under5", range(num_districts), lowBound=0, cat='Continuous')
abs_diff_over85 = pulp.LpVariable.dicts("abs_diff_over85", range(num_districts), lowBound=0, cat='Continuous')

#Objective: Minimize Population Imbalance
prob += pulp.lpSum(abs_diff_pop[j] for j in range(num_districts))

#Each County Assigned to One District
for i in counties:
    prob += pulp.lpSum(x[i, j] for j in range(num_districts)) == 1

#Balance Population Across Districts
for j in range(num_districts):
    district_pop = pulp.lpSum(populations[i] * x[(i, j)] for i in counties)
    prob += district_pop - target_population <= abs_diff_pop[j]
    prob += target_population - district_pop <= abs_diff_pop[j]

#Balance Gender Ratios
for j in range(num_districts):
    district_male_pop = pulp.lpSum(male_population[i] * x[(i, j)] for i in counties)
    district_female_pop = pulp.lpSum(female_population[i] * x[(i, j)] for i in counties)
    prob += district_male_pop >= 0.45 * district_pop  # Ensure at least 45% male
    prob += district_female_pop >= 0.45 * district_pop  # Ensure at least 45% female

#Balance Age Distribution
for j in range(num_districts):
    district_under5_pop = pulp.lpSum(age_under5[i] * x[(i, j)] for i in counties)
    district_over85_pop = pulp.lpSum(age_85plus[i] * x[(i, j)] for i in counties)
    prob += district_under5_pop >= 0.05 * district_pop  # Ensure at least 5% young
    prob += district_over85_pop >= 0.05 * district_pop  # Ensure at least 5% elderly

# Contiguity constraint: Ensure that adjacent counties stay together
for i in counties:
    for k in counties:
        if adjacency_matrix.loc[i, k] == 1:  # If counties i and k are adjacent
            for j in range(num_districts):
                prob += x[i, j] - x[k, j] <= 0  # Ensure at least one common neighbor

print("GDF STCOFIPS:", gdf["STCOFIPS"].unique())
print("Demographics COUNTY:", demographics_df["COUNTY"].unique())

print(base_model_df.index.duplicated().sum(), "Duplicate rows in index!")

print("Columns in base_model_df:", base_model_df.columns)
print("Columns in gdf:", gdf.columns)

base_model_df = base_model_df.drop_duplicates(subset="STCOFIPS")
base_model_df = base_model_df.set_index("STCOFIPS")

#Solve problem
print("Solving...")
prob.solve()
print(f"Status: {pulp.LpStatus[prob.status]}")